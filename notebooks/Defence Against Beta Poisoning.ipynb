{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0df38140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96d98452",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "173d8021",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path of the generated samples by beta poisoning attack\n",
    "CIFAR_GEN_SAMPLES_PATH = \"\"\n",
    "MNIST_GEN_SAMPLES_PATH = \"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ffdaae0",
   "metadata": {},
   "source": [
    "### Load MNIST real/adversarial samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0abf9d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_gen_samples = []\n",
    "\n",
    "for class_folder in os.scandir(MNIST_GEN_SAMPLES_PATH):\n",
    "    for sample in os.scandir(class_folder):\n",
    "        with open(sample, \"rb\") as f:\n",
    "            sample = pickle.load(f)\n",
    "            mnist_gen_samples.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "422e2883",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_gen_samples = np.vstack(mnist_gen_samples)\n",
    "\n",
    "mnist_gen_samples = mnist_gen_samples.reshape(mnist_gen_samples.shape[0], 28, 28, 1).astype('float32')\n",
    "mnist_gen_samples = (mnist_gen_samples - 127.5) / 127.5  # Normalize the images to [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dd2c5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(_, _), (mnist_test_images, mnist_test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce2bbeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test_images = mnist_test_images.reshape(mnist_test_images.shape[0], 28, 28, 1).astype('float32')\n",
    "mnist_test_images = (mnist_test_images - 127.5) / 127.5  # Normalize the images to [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4025d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_real_samples = mnist_test_images[0:len(mnist_gen_samples), :, :, :]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17f832e6",
   "metadata": {},
   "source": [
    "### Load CIFAR-10 real/adversarial samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1cd79874",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_gen_samples = []\n",
    "\n",
    "for class_folder in os.scandir(CIFAR_GEN_SAMPLES_PATH):\n",
    "    for sample in os.scandir(class_folder):\n",
    "        with open(sample, \"rb\") as f:\n",
    "            sample = pickle.load(f)\n",
    "            cifar_gen_samples.append(transforms.ToPILImage()(sample.reshape(3, 32, 32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0a3085ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is important to normalize the images for the discriminator to work properly.\n",
    "\n",
    "cifar_transform =  transforms.Compose(\n",
    "                    [transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "74b57e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_gen_samples = [torch.unsqueeze(cifar_transform(x), dim=0) for x in cifar_gen_samples]\n",
    "cifar_gen_samples = torch.cat(cifar_gen_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "16700493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# We can use an image folder dataset the way we have it setup.\n",
    "# Create the dataset\n",
    "cifar_test_dataset = torchvision.datasets.CIFAR10(\"./cifar10\", transform=cifar_transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9dff421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_dataloader = torch.utils.data.DataLoader(cifar_test_dataset, batch_size=len(cifar_gen_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "60148a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_real_samples = next(iter(cifar_dataloader))[0].to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9cbda793",
   "metadata": {},
   "source": [
    "### Discriminator model for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28159932",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "mnist_discriminator = tf.keras.models.load_model('../discriminator_models/mnist-discriminator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab48e1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for the MNIST discriminator\n",
      "Precision:  0.9982993197278912\n",
      "Recall:  1.0\n",
      "F1:  0.9991489361702128\n",
      "Accuracy:  0.9991482112436116\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.1 #Refer to the paper for the threshold value\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    mnist_real_outputs = mnist_discriminator(mnist_real_samples, training=False)\n",
    "    mnist_fake_outputs = mnist_discriminator(mnist_gen_samples, training=False)\n",
    "    \n",
    "mnist_precision_hist = []\n",
    "mnist_recall_hist = []\n",
    "mnist_f1_hist = []\n",
    "mnist_accuracy_hist = []\n",
    "\n",
    "\n",
    "tp = (mnist_fake_outputs < threshold).numpy().sum()\n",
    "fp = (mnist_real_outputs < threshold).numpy().sum()\n",
    "tn = (mnist_real_outputs > threshold).numpy().sum()\n",
    "fn = (mnist_fake_outputs > threshold).numpy().sum()\n",
    "\n",
    "\n",
    "precision = (tp) / (tp + fp)\n",
    "recall = (tp) / (tp + fn)\n",
    "f1 = (2*precision*recall) / (precision + recall)\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "print(\"Results for the MNIST discriminator\")\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c47963ca",
   "metadata": {},
   "source": [
    "### Discriminator model for CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "044f72aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (main): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(256, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (9): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_size = 32\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "\n",
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 4, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "    \n",
    "# cifar_discriminator = torch.load(\"../discriminator_models/cifar_discriminator.pt\")\n",
    "# cifar_discriminator.to(device)\n",
    "# cifar_discriminator.eval()\n",
    "\n",
    "cifar_discriminator = Discriminator(0).to(device)\n",
    "checkpoint = torch.load(f\"../discriminator_models/cifar_discriminator.pt\")\n",
    "cifar_discriminator.load_state_dict(checkpoint['state_dict'])\n",
    "cifar_discriminator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "99f0257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_real_outputs = cifar_discriminator(cifar_real_samples.reshape(-1, 3, 32, 32))\n",
    "cifar_fake_outputs = cifar_discriminator(cifar_gen_samples.reshape(-1, 3, 32, 32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1488046e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for the CIFAR-10 discriminator\n",
      "Precision:  0.9014522821576764\n",
      "Recall:  0.9720357941834452\n",
      "F1:  0.9354144241119484\n",
      "Accuracy:  0.9328859060402684\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.36 #Refer to the paper for the threshold value\n",
    "\n",
    "tp = (cifar_fake_outputs < threshold).numpy().sum()\n",
    "fp = (cifar_real_outputs < threshold).numpy().sum()\n",
    "tn = (cifar_real_outputs > threshold).numpy().sum()\n",
    "fn = (cifar_fake_outputs > threshold).numpy().sum()\n",
    "\n",
    "\n",
    "precision = (tp) / (tp + fp)\n",
    "recall = (tp) / (tp + fn)\n",
    "f1 = (2*precision*recall) / (precision + recall)\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "print(\"Results for the CIFAR-10 discriminator\")\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "b7765ceeab2682aeff90f785cce55ae4b35d72b281a63346ed896e5b68bf02d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
